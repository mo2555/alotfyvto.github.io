import * as tf from '@tensorflow/tfjs-core';
import { GraphModel } from '@tensorflow/tfjs-converter/dist/executor/graph_model';

interface Point2D {
    x: number;
    y: number;
}
interface Point3D {
    x: number;
    y: number;
    z: number;
}
type Coord2D = [number, number];
type Coord3D = [number, number, number];
type Matrix3x3 = [Coord3D, Coord3D, Coord3D];
type Quaternion = [number, number, number, number];
interface Size {
    width: number;
    height: number;
}
interface Rect {
    xy: Point2D;
    size: Size;
}
type Box = [Coord2D, Coord2D];
type ImageInput = ImageData | ImageBytes | ImageBitmap | HTMLCanvasElement;
interface ImageBytes {
    data: Uint8Array;
    width: number;
    height: number;
}
declare function rectIoU(r0: Rect, r1: Rect): number;
declare function boxIoU(b0: Box, b1: Box): number;

interface BodyDetection {
    points: Coord2D[];
    box: Box;
    score: number;
}
interface BodyCircle {
    center: Coord2D;
    top: Coord2D;
}
declare class BodyDetector {
    private model;
    private modelSize;
    private modelRatio;
    private anchorsX;
    private anchorsY;
    private anchorsData;
    private posesMax;
    private iouThresh;
    private scoreThresh;
    constructor(model: GraphModel);
    process(image: tf.Tensor4D): Promise<BodyDetection[]>;
    decodeBoxes(pred: tf.Tensor2D, anchors: [tf.Tensor1D, tf.Tensor1D], size: Size): tf.Tensor2D;
    buildAnchors(size: Size): Point2D[];
    prepare(): Promise<void>;
    dispose(): void;
}

interface PosePoint {
    pixel: Coord3D;
    metric: Coord3D;
    score: number;
    visibility: number;
}
interface PoseDetection {
    keypoints: PosePoint[];
    score: number;
    center: Coord2D;
    top: Coord2D;
    mask?: {
        buffer: Uint8Array;
        size: Size;
        box: Box;
    };
    debug?: {
        center: Coord2D;
        top: Coord2D;
        box: Box;
        radius: number;
        angle: number;
    };
}
declare class PoseDetector {
    private model;
    private mask;
    private modelSize;
    private sizeFactor;
    constructor(model: GraphModel, mask?: boolean);
    process(image: tf.Tensor4D, detections: BodyCircle[]): Promise<PoseDetection[]>;
    private refinePoints;
    private rotatedRect;
    prepare(): Promise<void>;
    dispose(): Promise<void>;
}

interface FilterParams$1 {
    minCutOff: number;
    minCutOffD: number;
    beta: number;
}
declare class PoseFilter {
    protected freq: number;
    readonly pixelParams: FilterParams$1;
    readonly metricParams: FilterParams$1;
    readonly boxParams: FilterParams$1;
    readonly scoreCutOff = 1;
    readonly visibilityCutOff = 1;
    protected raw?: PoseDetection;
    protected smooth?: PoseDetection;
    protected der?: PoseDetection;
    protected time: number;
    filter(val: PoseDetection, time: number, scale?: number): PoseDetection;
    protected filterKeypoints(val: PosePoint[], raw: PosePoint[], der: PosePoint[], smooth: PosePoint[], scale: number): void;
    protected filterCoord3D(val: Coord3D, raw: Coord3D, der: Coord3D, smooth: Coord3D, scale: number, params: FilterParams$1): void;
    protected filterCoord2D(val: Coord2D, raw: Coord2D, der: Coord2D, smooth: Coord2D, scale: number, params: FilterParams$1): void;
    protected reset(): void;
    protected alpha(cutOff: number): number;
    protected clonePose(v: PoseDetection): PoseDetection;
}

declare class PoseTracker {
    protected bodyDetector?: BodyDetector;
    protected poseDetector?: PoseDetector;
    protected poseModule?: any;
    protected poseAligner?: any;
    protected bodyTracks: BodyCircle[];
    protected poseFilters: PoseFilter[];
    protected angle: number;
    protected ratio: number;
    protected near: number;
    readonly poseScore = 0.6;
    readonly alignScore = 0.9;
    readonly alignVisibility = 0.9;
    protected skipCount: number;
    readonly skipMax = 2;
    process(input: ImageInput, timestamp?: number): Promise<PoseDetection[]>;
    setCamera(angle: number, ratio: number, near?: number): void;
    init(token: string, root?: string, cache?: boolean, mask?: boolean, backend?: "webgl" | "cpu"): Promise<void>;
    reset(): void;
    prepare(): Promise<void>;
    dispose(): void;
}

interface FaceDetection {
    rect: Rect;
    score: number;
    keypoints?: Point2D[];
}
declare class FaceDetector {
    private model;
    private modelSize;
    private modelRatio;
    private anchors;
    private anchorsData;
    private size;
    private facesMax;
    private iouThresh;
    private scoreThresh;
    private keypointCount;
    constructor(model: GraphModel);
    process(image: tf.Tensor4D, keypoints?: boolean): Promise<FaceDetection[]>;
    decodeBoxes(pred: tf.Tensor2D, anchors: tf.Tensor2D, size: tf.Tensor1D): tf.Tensor2D;
    buildAnchors(size: Size): [number, number][];
    prepare(): Promise<void>;
    dispose(): void;
}
declare enum FacePoints {
    EyeR = 0,
    EyeL = 1,
    Nose = 2,
    Mouth = 3,
    EarR = 4,
    EarL = 5
}

interface MeshDetection {
    keypoints: Coord3D[];
    rect: [number, number, number, number];
    score: number;
}
interface FaceBox {
    rect: Rect;
    symmetry: [Point2D, Point2D];
}
declare class MeshDetector {
    private model;
    private modelSize;
    private modelHighP;
    private boxFactor;
    symmetryPoints: number[];
    constructor(model: GraphModel);
    process(image: tf.Tensor4D, detections: FaceBox[]): Promise<{
        keypoints: Coord3D[];
        score: number;
        rect: [number, number, number, number];
    }[]>;
    private rotatedRect;
    prepare(): Promise<void>;
    dispose(): void;
}
declare function scaleMesh(mesh: MeshDetection, factor: number): MeshDetection;

interface FacePose {
    rotation: Quaternion;
    translation: Coord3D;
    scale: number;
    shapeScale: Coord3D;
}
declare class FaceTracker {
    protected faceDetector?: FaceDetector;
    protected meshDetector?: MeshDetector;
    protected faceModule?: any;
    protected faceAligner?: any;
    protected faceTracks: FaceBox[];
    protected faceFilters: any[];
    readonly meshScore = 0.9;
    process(input: ImageInput, timestamp?: number): Promise<MeshDetection[]>;
    align(model: Coord3D[]): FacePose | undefined;
    alignTransform(): FacePose | undefined;
    metricPoints(): Coord3D[] | undefined;
    referencePoints(): Coord3D[] | undefined;
    backprojPoints(): Coord3D[] | undefined;
    setCamera(angle: number, ratio: number, near: number): void;
    init(token: string, root?: string, cache?: boolean, highp?: boolean, backend?: "webgl" | "cpu"): Promise<void>;
    reset(): void;
    prepare(): Promise<void>;
    dispose(): void;
}

interface PalmDetection {
    points: Coord2D[];
    box: Box;
    score: number;
}
interface PalmBox {
    box: Box;
    points: Coord2D[];
    start: Coord2D;
    end: Coord2D;
}
declare class PalmDetector {
    private model;
    private modelSize;
    private modelRatio;
    private anchorsX;
    private anchorsY;
    private anchorsData;
    private handsMax;
    private iouThresh;
    private scoreThresh;
    constructor(model: GraphModel);
    process(image: tf.Tensor4D): Promise<PalmDetection[]>;
    decodeBoxes(pred: tf.Tensor2D, anchors: [tf.Tensor1D, tf.Tensor1D], size: Size): tf.Tensor2D;
    buildAnchors(size: Size): Point2D[];
    prepare(): Promise<void>;
    dispose(): void;
}

interface HandPoint {
    pixel: Coord3D;
    metric: Coord3D;
}
interface WristLine {
    point: Coord2D;
    vector: Coord2D;
}
interface WristDetection {
    lines: WristLine[];
}
interface HandDetection {
    keypoints: HandPoint[];
    score: number;
    handedness: number;
    wrist: WristDetection;
    debug?: {
        box: PalmBox;
        circle: Coord2D[];
        anchors: Coord2D[];
        tensors?: {
            mask: Uint8Array;
            edge: Uint8Array;
            rgb: Uint8Array;
        };
    };
}
declare class HandDetector {
    private model;
    private wrist;
    private modelSize;
    private modelRatio;
    private backend?;
    private localMax?;
    private localMaxSize;
    private circlePoints;
    readonly colorWeights: number[];
    readonly colorThresh = 0.05;
    readonly edgeThresh = 0.003;
    readonly edgeStop = 0.01;
    constructor(model: GraphModel, wrist?: boolean);
    process(image: tf.Tensor4D, detections: PalmBox[]): Promise<HandDetection[]>;
    private evaluateLine;
    private fitLine;
    private normalizeLines;
    private buildLine;
    private buildCircle;
    private rotatedRect;
    prepare(): Promise<void>;
    dispose(): Promise<void>;
}

interface FilterParams {
    minCutOff: number;
    minCutOffD: number;
    beta: number;
}
declare class HandFilter {
    protected freq: number;
    readonly pixelParams: FilterParams;
    readonly metricParams: FilterParams;
    readonly scoreCutOff = 1;
    readonly visibilityCutOff = 1;
    protected raw?: HandDetection;
    protected smooth?: HandDetection;
    protected der?: HandDetection;
    protected time: number;
    filter(val: HandDetection, time: number, scale?: number): HandDetection;
    protected filterKeypoints(val: HandPoint[], raw: HandPoint[], der: HandPoint[], smooth: HandPoint[], scale: number): void;
    protected filterCoord3D(val: Coord3D, raw: Coord3D, der: Coord3D, smooth: Coord3D, scale: number, params: FilterParams): void;
    protected filterCoord2D(val: Coord2D, raw: Coord2D, der: Coord2D, smooth: Coord2D, scale: number, params: FilterParams): void;
    protected reset(): void;
    protected alpha(cutOff: number): number;
    protected clonePose(v: HandDetection): HandDetection;
}

declare class HandTracker {
    protected palmDetector?: PalmDetector;
    protected handDetector?: HandDetector;
    protected handTracks: PalmBox[];
    protected handFilters: HandFilter[];
    protected angle: number;
    protected ratio: number;
    protected near: number;
    readonly handScore = 0.55;
    process(input: ImageInput, timestamp?: number): Promise<HandDetection[]>;
    protected align(keypoints: HandPoint[]): void;
    setCamera(angle: number, ratio: number, near?: number): void;
    init(token: string, root?: string, cache?: boolean, backend?: "webgl" | "cpu"): Promise<void>;
    reset(): void;
    prepare(): Promise<void>;
    dispose(): void;
}

declare const meshDesc: {
    [key: string]: number[];
};
declare const meshTriangles: number[];
declare const meshUV: Coord2D[];
declare const meshReference: Coord3D[];

declare class MeanColor {
    canvas?: HTMLCanvasElement;
    protected context: CanvasRenderingContext2D | null;
    constructor();
    mean(image: HTMLCanvasElement): number[] | undefined;
    brightness(image: HTMLCanvasElement): number | undefined;
    dispose(): void;
}

export { BodyCircle, BodyDetection, BodyDetector, Box, Coord2D, Coord3D, FaceBox, FaceDetection, FaceDetector, FacePoints, FacePose, FaceTracker, HandDetection, HandDetector, HandPoint, HandTracker, ImageBytes, ImageInput, Matrix3x3, MeanColor, MeshDetection, MeshDetector, PalmBox, PalmDetection, PalmDetector, Point2D, Point3D, PoseDetection, PoseDetector, PosePoint, PoseTracker, Quaternion, Rect, Size, WristDetection, WristLine, boxIoU, meshDesc, meshReference, meshTriangles, meshUV, rectIoU, scaleMesh };
